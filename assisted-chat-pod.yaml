apiVersion: v1
kind: Pod
metadata:
  name: assisted-chat-pod
spec:
  containers:
    - name: lightspeed-stack
      image: localhost/local-ai-chat-lightspeed-stack-plus-llama-stack
      env:
        - name: GEMINI_API_KEY
          value: ${GEMINI_API_KEY}
      ports:
        - containerPort: 8090
          hostPort: 8090
      volumeMounts:
        - mountPath: /app-root/lightspeed-stack.yaml
          name: config
          subPath: lightspeed-stack.yaml
        - mountPath: /app-root/llama_stack_client_config.yaml
          name: config
          subPath: llama_stack_client_config.yaml
    - name: assisted-service-mcp
      image: localhost/local-ai-chat-assisted-service-mcp:latest
      env:
        - name: OFFLINE_TOKEN
          value: ${OCM_TOKEN}
    - name: ui
      image: localhost/local-ai-chat-ui
    - name: mcp-inspector
      image: localhost/local-ai-chat-inspector:latest
      ports:
        - containerPort: 6274
          hostPort: 6274
  volumes:
    - name: config
      hostPath:
        path: ./config
        type: Directory
